{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 3, 416, 416).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunjian.png', 'dog.jpg', 'assignment.png']\n",
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "tf = transforms.ToTensor()\n",
    "import os\n",
    "\n",
    "path = \"./assets\"\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)\n",
    "\n",
    "x = torch.tensor([])\n",
    "print(x.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14260/3021214073.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_t = torch.tensor(img_t)\n",
      "/tmp/ipykernel_14260/3021214073.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_t = torch.tensor(img_t)\n"
     ]
    }
   ],
   "source": [
    "img = PIL.Image.open(path + '/' + file_list[0])\n",
    "img = img.resize((416, 416))\n",
    "img_t = tf(img)\n",
    "img_t = torch.tensor(img_t) \n",
    "img_t = img_t.unsqueeze(0)\n",
    "result = img_t\n",
    "\n",
    "for name in file_list:\n",
    "    img = PIL.Image.open(path + '/' + name)\n",
    "    img = img.resize((416, 416))\n",
    "    img_t = tf(img)\n",
    "    img_t = torch.tensor(img_t) \n",
    "    img_t = img_t.unsqueeze(0)\n",
    "    result = torch.cat((result, img_t))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2235, 0.2353, 0.2431,  ..., 0.7765, 0.6157, 0.2902],\n",
      "         [0.2275, 0.2314, 0.2392,  ..., 0.7843, 0.5412, 0.2431],\n",
      "         [0.2314, 0.2314, 0.2392,  ..., 0.7686, 0.4196, 0.2157],\n",
      "         ...,\n",
      "         [0.6196, 0.6353, 0.6196,  ..., 0.5098, 0.4000, 0.2471],\n",
      "         [0.6314, 0.6235, 0.6039,  ..., 0.5098, 0.3490, 0.2275],\n",
      "         [0.6235, 0.6000, 0.6118,  ..., 0.5020, 0.3529, 0.2078]],\n",
      "\n",
      "        [[0.2275, 0.2392, 0.2471,  ..., 0.9490, 0.5137, 0.2157],\n",
      "         [0.2314, 0.2353, 0.2431,  ..., 0.9216, 0.4431, 0.2078],\n",
      "         [0.2353, 0.2353, 0.2431,  ..., 0.8627, 0.3216, 0.2235],\n",
      "         ...,\n",
      "         [0.6510, 0.6667, 0.6510,  ..., 0.4824, 0.3451, 0.2000],\n",
      "         [0.6627, 0.6549, 0.6353,  ..., 0.4784, 0.2863, 0.1804],\n",
      "         [0.6549, 0.6275, 0.6471,  ..., 0.4667, 0.2824, 0.1529]],\n",
      "\n",
      "        [[0.1961, 0.2078, 0.2157,  ..., 0.5333, 0.2706, 0.1608],\n",
      "         [0.2000, 0.2039, 0.2118,  ..., 0.5373, 0.2431, 0.1569],\n",
      "         [0.2039, 0.2039, 0.2118,  ..., 0.5137, 0.1922, 0.1804],\n",
      "         ...,\n",
      "         [0.6941, 0.7098, 0.6941,  ..., 0.4667, 0.3412, 0.1882],\n",
      "         [0.7059, 0.6980, 0.6784,  ..., 0.4667, 0.2824, 0.1647],\n",
      "         [0.6980, 0.6745, 0.6863,  ..., 0.4549, 0.2824, 0.1412]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8249/3875727173.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_t = torch.tensor(img_t)\n"
     ]
    }
   ],
   "source": [
    "img_t = tf(img)\n",
    "img_t = torch.tensor(img_t)\n",
    "print(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "img_t = img_t.unsqueeze(0)\n",
    "print(img_t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2235, 0.2353, 0.2431,  ..., 0.7765, 0.6157, 0.2902],\n",
      "          [0.2275, 0.2314, 0.2392,  ..., 0.7843, 0.5412, 0.2431],\n",
      "          [0.2314, 0.2314, 0.2392,  ..., 0.7686, 0.4196, 0.2157],\n",
      "          ...,\n",
      "          [0.6196, 0.6353, 0.6196,  ..., 0.5098, 0.4000, 0.2471],\n",
      "          [0.6314, 0.6235, 0.6039,  ..., 0.5098, 0.3490, 0.2275],\n",
      "          [0.6235, 0.6000, 0.6118,  ..., 0.5020, 0.3529, 0.2078]],\n",
      "\n",
      "         [[0.2275, 0.2392, 0.2471,  ..., 0.9490, 0.5137, 0.2157],\n",
      "          [0.2314, 0.2353, 0.2431,  ..., 0.9216, 0.4431, 0.2078],\n",
      "          [0.2353, 0.2353, 0.2431,  ..., 0.8627, 0.3216, 0.2235],\n",
      "          ...,\n",
      "          [0.6510, 0.6667, 0.6510,  ..., 0.4824, 0.3451, 0.2000],\n",
      "          [0.6627, 0.6549, 0.6353,  ..., 0.4784, 0.2863, 0.1804],\n",
      "          [0.6549, 0.6275, 0.6471,  ..., 0.4667, 0.2824, 0.1529]],\n",
      "\n",
      "         [[0.1961, 0.2078, 0.2157,  ..., 0.5333, 0.2706, 0.1608],\n",
      "          [0.2000, 0.2039, 0.2118,  ..., 0.5373, 0.2431, 0.1569],\n",
      "          [0.2039, 0.2039, 0.2118,  ..., 0.5137, 0.1922, 0.1804],\n",
      "          ...,\n",
      "          [0.6941, 0.7098, 0.6941,  ..., 0.4667, 0.3412, 0.1882],\n",
      "          [0.7059, 0.6980, 0.6784,  ..., 0.4667, 0.2824, 0.1647],\n",
      "          [0.6980, 0.6745, 0.6863,  ..., 0.4549, 0.2824, 0.1412]]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunjian.png', 'dog.jpg', 'demo.png', 'logo.png', 'git_fig.png', 'assignment.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./assets\"\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
